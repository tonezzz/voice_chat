x-build-cache: &build_cache
  cache_from:
    - type=local,src=${DOCKER_CACHE_DIR:-.docker-cache}
  cache_to:
    - type=local,dest=${DOCKER_CACHE_DIR:-.docker-cache},mode=max

x-service-defaults: &service_defaults
  restart: unless-stopped

x-healthcheck-fast: &healthcheck_fast
  interval: 30s
  timeout: 10s
  retries: 5

x-healthcheck-slow: &healthcheck_slow
  interval: 60s
  timeout: 10s
  retries: 3

services:
  mcp0:
    build:
      context: ./mcp0
      <<: *build_cache
    container_name: mcp0
    init: true
    <<: *service_defaults
    environment:
      - MCP0_HOST=0.0.0.0
      - MCP0_PORT=8010
      - MCP0_TIMEOUT_SECONDS=10
      - MCP0_ADMIN_TOKEN=${MCP0_ADMIN_TOKEN:-}
      - GITHUB_MCP_URL=${GITHUB_MCP_URL:-http://mcp-github:8080}
      - GITHUB_MCP_HEALTH_PATH=${GITHUB_MCP_HEALTH_PATH:-/health}
      - GITHUB_MCP_TOOLS=${GITHUB_MCP_TOOLS:-list_models+run_space}
      - GITHUB_MCP_TOKEN=${GITHUB_MCP_TOKEN:-}
      - GITHUB_PERSONAL_TOKEN=${GITHUB_PERSONAL_TOKEN:-}
      - GITHUB_WEBHOOK_SECRET=${GITHUB_WEBHOOK_SECRET:-}
      - GITHUB_WEBHOOK_TOOL=${GITHUB_WEBHOOK_TOOL:-run_space}
      - GITHUB_WEBHOOK_EVENTS=${GITHUB_WEBHOOK_EVENTS:-}
      - GITHUB_WEBHOOK_TOOL_MAP=${GITHUB_WEBHOOK_TOOL_MAP:-}
      - MCP0_PROVIDERS=githubModel:${GITHUB_MCP_URL:-http://mcp-github:8080}|health=${GITHUB_MCP_HEALTH_PATH:-/health}|health_method=GET|capabilities=/.well-known/mcp.json|tools=${GITHUB_MCP_TOOLS:-list_models+run_space},meeting:http://mcp-meeting:8008|health=/health|capabilities=/.well-known/mcp.json|tools=start_meeting+end_meeting+append_transcript+ingest_audio_chunk+get_meeting_notes+summarize_meeting+list_sessions
    ports:
      - "8010:8010"
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8010/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
  server:
    build: ./server
    container_name: voice-chat-server
    init: true
    <<: *service_defaults
    environment:
      - NODE_ENV=production
      - OLLAMA_URL=${OLLAMA_URL:-}
      - OLLAMA_GPU_URL=${OLLAMA_GPU_URL:-}
      - MODEL=${OLLAMA_MODEL:-llama3.2:3b}
      - PORT=3001
      - STT_URL=${STT_URL:-}
      - STT_GPU_URL=${STT_GPU_URL:-}
      - OPENVOICE_URL=${OPENVOICE_URL:-}
      - OPENVOICE_GPU_URL=${OPENVOICE_GPU_URL:-}
      - YOLO_MCP_URL=${YOLO_MCP_URL:-}
      - BSLIP_MCP_URL=${BSLIP_MCP_URL:-}
      - IMAGE_MCP_URL=${IMAGE_MCP_URL:-}
      - IMAGE_MCP_GPU_URL=${IMAGE_MCP_GPU_URL:-http://imagen-gpu:8001}
      - DNSTOOLS_MCP_URL=${DNSTOOLS_MCP_URL:-http://mcp-dnstools:8018}
      - MEMORY_MCP_URL=${MEMORY_MCP_URL:-http://mcp-memory:8020}
      - VAJA_MCP_URL=${VAJA_MCP_URL:-http://mcp-vaja:8017}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - ENABLE_REDIS_CACHE=${ENABLE_REDIS_CACHE:-true}
      - REDIS_CACHE_TTL_SECONDS=${REDIS_CACHE_TTL_SECONDS:-300}
      - IDP_MCP_URL=${IDP_MCP_URL:-}
      - IDP_MCP_GPU_URL=${IDP_MCP_GPU_URL:-}
      - MEETING_MCP_URL=${MEETING_MCP_URL:-http://mcp-meeting:8008}
      - MEMENTO_MCP_URL=${MEMENTO_MCP_URL:-}
      - MCP0_URL=http://mcp0:8010
      - GITHUB_MCP_URL=${GITHUB_MCP_URL:-http://mcp-github:8080}
      - GITHUB_MCP_HEALTH_PATH=${GITHUB_MCP_HEALTH_PATH:-/health}
      - GITHUB_MCP_TOKEN=${GITHUB_MCP_TOKEN:-}
      - GITHUB_PERSONAL_TOKEN=${GITHUB_PERSONAL_TOKEN:-}
      - GITHUB_MODEL_TOKEN=${GITHUB_MODEL_TOKEN:-}
      - GITHUB_MODEL=${GITHUB_MODEL:-}
      - GITHUB_MODEL_DEPLOYMENT=${GITHUB_MODEL_DEPLOYMENT:-}
      - GITHUB_MODEL_CHAT_BASE_URL=${GITHUB_MODEL_CHAT_BASE_URL:-}
      - GITHUB_MODEL_CHAT_URL=${GITHUB_MODEL_CHAT_URL:-}
      - GITHUB_MODEL_TEMPERATURE=${GITHUB_MODEL_TEMPERATURE:-}
      - GITHUB_MODEL_MAX_TOKENS=${GITHUB_MODEL_MAX_TOKENS:-}
      - GITHUB_API_VERSION=${GITHUB_API_VERSION:-}
      - GPU_WORKER_TOKEN=${GPU_WORKER_TOKEN:-}
      - GPU_MAX_PENDING_JOBS=${GPU_MAX_PENDING_JOBS:-100}
      - GPU_JOB_LEASE_SECONDS=${GPU_JOB_LEASE_SECONDS:-900}
      - LLM_PROVIDER=${LLM_PROVIDER:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - ANTHROPIC_MODEL=${ANTHROPIC_MODEL:-claude-3-5-sonnet-20241022}
      - ANTHROPIC_VERSION=${ANTHROPIC_VERSION:-2023-06-01}
      - ANTHROPIC_MAX_TOKENS=${ANTHROPIC_MAX_TOKENS:-1024}
      - ANTHROPIC_TEMPERATURE=${ANTHROPIC_TEMPERATURE:-0.2}
      - TUYA_MCP_URL=${TUYA_MCP_URL:-http://mcp-tuya:8007}
      - ENABLE_VOICE_FEATURE=false
      - CARWATCH_SNAPSHOT_TTL_MS=600000
    ports:
      - "3002:3001"
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:3001/health || exit 1"]
      interval: 60s
      timeout: 10s
      retries: 5
    depends_on:
      - imagen-gpu
      - redis

  a_kakk:
    image: nginx:stable-alpine
    container_name: a-kakk
    <<: *service_defaults
    volumes:
      - C:\_dev\_models\a_kakk:/usr/share/nginx/html:ro
      - C:\_dev\_models\a_kakk\config\default.conf:/etc/nginx/conf.d/default.conf:ro
      - C:\_dev\_models\tony\logs\a-kakk:/var/log/nginx
    ports:
      - "4173:80"
    depends_on:
      - server

  localtunnel:
    image: node:22-alpine
    container_name: voice-chat-localtunnel
    <<: *service_defaults
    working_dir: /app
    volumes:
      - ./localtunnel/entrypoint.sh:/app/entrypoint.sh:ro
    environment:
      - LT_PORT=${LT_PORT:-4173}
      - LT_HOST=${LT_HOST:-a_kakk}
      - LT_SUBDOMAIN=${LT_SUBDOMAIN:-chaba}
    entrypoint: ["/bin/sh", "/app/entrypoint.sh"]
    depends_on:
      - a_kakk

  caddy:
    build:
      context: ./caddy
    container_name: kk1-caddy
    <<: *service_defaults
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy-config:/config
      - caddy-data:/data
    environment:
      - CLOUDFLARE_API_TOKEN=${CLOUDFLARE_API_TOKEN:-}
    depends_on:
      - a_kakk

  a_chaba:
    image: nginx:stable-alpine
    container_name: a-chaba
    <<: *service_defaults
    volumes:
      - C:\_dev\_models\a_chaba:/usr/share/nginx/html:ro
      - C:\_dev\_models\a_chaba\config\default.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "4174:80"
    depends_on:
      - server

  edge:
    image: nginx:stable-alpine
    container_name: voice-chat-edge
    <<: *service_defaults
    volumes:
      - ./nginx/edge.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "8080:80"
    depends_on:
      - server
      - a_kakk
      - a_chaba

  imagen-gpu:
    build:
      context: ./mcp_imagen
      args:
        BASE_IMAGE_PY: ${PYTHON_BASE_IMAGE:-python:3.11-slim}
        CUDA_BASE_IMAGE: ${CUDA_BASE_IMAGE:-nvidia/cuda:12.4.1-runtime-ubuntu22.04}
        USE_GPU: "true"
      <<: *build_cache
    container_name: imagen-gpu
    <<: *service_defaults
    environment:
      - USE_GPU=true
      - TORCH_DEVICE=cuda
      - IMAGE_MODEL_ID=${IMAGE_MODEL_ID:-runwayml/stable-diffusion-v1-5}
      - IMAGE_MODEL_CACHE=/app/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - imagen-cache:/app/models
      - ${DIFFUSERS_CACHE_ROOT:-C:/_dev/_models/diffusers}:/app/models
    ports:
      - "8001:8001"
    healthcheck:
      <<: *healthcheck_fast
      test: ["CMD-SHELL", "curl -sf http://localhost:8001/health || exit 1"]

  mcp-meeting:
    build:
      context: ./mcp_meeting
      <<: *build_cache
    container_name: mcp-meeting
    <<: *service_defaults
    environment:
      - PORT=8008
      - MEETING_STT_URL=${MEETING_STT_URL:-}
      - MEETING_STT_HEALTH_PATH=${MEETING_STT_HEALTH_PATH:-/health}
      - MEETING_MAX_SEGMENTS=${MEETING_MAX_SEGMENTS:-1500}
      - MEETING_SUMMARY_MAX_ENTRIES=${MEETING_SUMMARY_MAX_ENTRIES:-20}
      - MEETING_DEFAULT_LANGUAGE=${MEETING_DEFAULT_LANGUAGE:-}
      - MEETING_DEFAULT_WHISPER_MODEL=${MEETING_DEFAULT_WHISPER_MODEL:-}
      - MEETING_STORAGE_PATH=${MEETING_STORAGE_PATH:-/data/meetings.json}
    ports:
      - "8008:8008"
    volumes:
      - ${MEETING_STORAGE_ROOT:-C:/_dev/_models/meeting}:/data
    healthcheck:
      <<: *healthcheck_fast
      test: ["CMD-SHELL", "curl -sf http://localhost:8008/health || exit 1"]

  mcp-github:
    build:
      context: ./mcp_github_bridge
      <<: *build_cache
    container_name: mcp-github
    <<: *service_defaults
    environment:
      - GITHUB_PERSONAL_TOKEN=${GITHUB_PERSONAL_TOKEN:-}
      - GITHUB_PERSONAL_ACCESS_TOKEN=${GITHUB_PERSONAL_TOKEN:-}
      - GITHUB_TOOLSETS=${GITHUB_TOOLSETS:-default}
      - LOG_LEVEL=${GITHUB_MCP_BRIDGE_LOG_LEVEL:-INFO}
      - GITHUB_WEBHOOK_SECRET=${GITHUB_WEBHOOK_SECRET:-}
      - GITHUB_WEBHOOK_TOOL=${GITHUB_WEBHOOK_TOOL:-run_space}
      - GITHUB_WEBHOOK_EVENTS=${GITHUB_WEBHOOK_EVENTS:-}
      - GITHUB_WEBHOOK_TOOL_MAP=${GITHUB_WEBHOOK_TOOL_MAP:-}
      - GITHUB_TOOLSETS=${GITHUB_TOOLSETS:-default,models}

    ports:
      - "8200:8080"
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8080/health || exit 1"]

  mcp-seqthink:
    build:
      context: ./mcp_seqthink
      <<: *build_cache
    container_name: mcp-seqthink
    <<: *service_defaults
    environment:
      - PORT=8015
      - SEQTHINK_PROVIDER_NAME=${SEQTHINK_PROVIDER_NAME:-seqthink}
      - SEQTHINK_BASE_URL=${SEQTHINK_BASE_URL:-http://mcp-seqthink:8015}
      - MCP0_URL=http://mcp0:8010
      - MCP0_ADMIN_TOKEN=${MCP0_ADMIN_TOKEN:-}
    ports:
      - "8015:8015"
    healthcheck:
      <<: *healthcheck_slow
      test: ["CMD-SHELL", "curl -sf http://localhost:8015/health || exit 1"]

  mcp-dnstools:
    build:
      context: ./mcp_dnstools
      <<: *build_cache
    container_name: mcp-dnstools
    <<: *service_defaults
    environment:
      - PORT=8018
      - DNSTOOLS_PROVIDER_NAME=${DNSTOOLS_PROVIDER_NAME:-dnstools}
      - DNSTOOLS_NAMESERVERS=${DNSTOOLS_NAMESERVERS:-1.1.1.1,8.8.8.8}
      - DNSTOOLS_ENABLE_DOH=${DNSTOOLS_ENABLE_DOH:-true}
      - DNSTOOLS_DOH_ENDPOINT=${DNSTOOLS_DOH_ENDPOINT:-https://dns.google/resolve}
      - DNSTOOLS_HEALTH_DOMAIN=${DNSTOOLS_HEALTH_DOMAIN:-example.com}
      - DNSTOOLS_SUMMARY_TYPES=${DNSTOOLS_SUMMARY_TYPES:-A,AAAA,CNAME,MX,TXT,NS,SOA}
      - MCP0_URL=http://mcp0:8010
      - MCP0_ADMIN_TOKEN=${MCP0_ADMIN_TOKEN:-}
    ports:
      - "8018:8018"
    healthcheck:
      <<: *healthcheck_fast
      test: ["CMD-SHELL", "curl -sf http://localhost:8018/health || exit 1"]

  mcp-memory:
    build:
      context: ./mcp_memory
      <<: *build_cache
    container_name: mcp-memory
    <<: *service_defaults
    environment:
      - PORT=8020
      - MEMORY_FILE_PATH=${MEMORY_FILE_PATH:-/data/memory.jsonl}
      - MEMORY_PROVIDER_NAME=${MEMORY_PROVIDER_NAME:-memory}
      - MEMORY_BASE_URL=${MEMORY_BASE_URL:-http://mcp-memory:8020}
      - MEMORY_DEFAULT_TOOLS=${MEMORY_DEFAULT_TOOLS:-create_entities,create_relations,add_observations,delete_entities,delete_observations,delete_relations,read_graph,search_nodes,open_nodes}
      - MCP0_URL=http://mcp0:8010
      - MCP0_ADMIN_TOKEN=${MCP0_ADMIN_TOKEN:-}
    volumes:
      - ${MEMORY_STORAGE_ROOT:-C:/_dev/_models/memory}:/data
    ports:
      - "8020:8020"
    healthcheck:
      <<: *healthcheck_fast
      test: ["CMD-SHELL", "curl -sf http://localhost:8020/health || exit 1"]

  mcp-vaja:
    build:
      context: .
      dockerfile: ./mcp_vaja/Dockerfile
      <<: *build_cache
    container_name: mcp-vaja
    <<: *service_defaults
    environment:
      - PORT=8017
      - AI4THAI_API_KEY=${AI4THAI_API_KEY:-}
      - VAJA_ENDPOINT=${VAJA_ENDPOINT:-https://api.aiforthai.in.th/vaja}
      - VAJA_OUTPUT_DIR=/output
    volumes:
      - ${VAJA_OUTPUT_DIR:-C:/_dev/_models/vaja_audio}:/output
    ports:
      - "8017:8017"
    healthcheck:
      <<: *healthcheck_fast
      test: ["CMD-SHELL", "curl -sf http://localhost:8017/health || exit 1"]

  ngrok:
    image: ngrok/ngrok:latest
    container_name: voice-chat-ngrok
    <<: *service_defaults
    environment:
      - NGROK_AUTHTOKEN=${NGROK_AUTHTOKEN}
    volumes:
      - ./ngrok/ngrok.yml:/etc/ngrok/ngrok.yml:ro
    command:
      - start
      - --all
      - --config
      - /etc/ngrok/ngrok.yml
      - --log
      - stdout
      - --log-level
      - debug
    depends_on:
      - server

  redis:
    image: redis:7-alpine
    container_name: voice-chat-redis
    <<: *service_defaults
    command: ["redis-server", "--save", "60", "1", "--loglevel", "warning"]
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  imagen-cache:
  redis-data:
  caddy-config:
  caddy-data:
